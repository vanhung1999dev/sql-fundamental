# üß† What DISTINCT Really Does (Deep Dive)

`DISTINCT` removes duplicate rows in the result set.

But the ‚Äúhow‚Äù depends on: <br>
- number of rows
- size of rows
- available memory
- whether the query has `ORDER BY`
- whether the DISTINCT columns have `indexes`

PostgreSQL switches between two internal strategies: <br>
- `Hash-based distinct`
- `Sort-based distinct`

## üîç 1. Hash-Based DISTINCT (fastest path)
PostgreSQL tries to use a HashAggregate whenever possible. <br>

### How it works internally

- Reads each row from the scan (seq scan / index scan / join output)
- Creates a hash key based on DISTINCT columns
- Inserts it into an in-memory hash table
- If the key already exists ‚Üí row is skipped
- Final output is all unique keys

#### Example EXPLAIN
```sql
SELECT DISTINCT city FROM users;
```

Plan may show: <br>
```
HashAggregate
  -> Seq Scan on users

```

### When hash-based is used:
- No `ORDER BY`
- `DISTINCT` columns are hashable
- Enough memory (`controlled by work_mem`)

### Memory behavior
- If the hash table exceeds `work_mem`, PostgreSQL starts `spilling to disk`, meaning:
- worse performance
- temporary files created

## üîç 2. Sort + Unique (Sort-Based DISTINCT)
If PostgreSQL cannot use hashing or you force an ORDER, it uses sorting.

### How it works internally
- Scan input rows
- Sort rows by DISTINCT columns
- Walk through sorted list
- Keep first of each group ‚Üí remove duplicates

Plan: <br>
```sql
Unique
  -> Sort
       -> Seq Scan on ...

```

### When sort-based is used
- Query includes `ORDER BY`
- DISTINCT cannot be hashed (rare)
- Planner estimates `SORT cheaper than HASH`
- `DISTINCT ON` (requires sorting)

### Disk behavior
- If sorted data > work_mem, PostgreSQL uses:
- external merge sort
- temporary files

# üî• Performance Tips You Need as a Data Engineer

## 1. Indexes can avoid sorting
If DISTINCT columns have a matching index: <br>

```sql

CREATE INDEX idx_users_email ON users(email);

SELECT DISTINCT email FROM users;

```

Planner can use: <br>

```
Unique
  -> Index Only Scan on users(email)

```

This avoids: <br>
- sorting
- hashing
- reading full table
- Huge performance boost.

## 2. DISTINCT vs GROUP BY (same result, different planner choices)

```sql
SELECT DISTINCT email FROM users;
SELECT email FROM users GROUP BY email;

```

- But their performance may differ depending on planner estimates.
- GROUP BY sometimes prefers HashAggregate even when DISTINCT would sort.

## 3. DISTINCT with SELECT * forces row comparison

```sql
SELECT DISTINCT * FROM users;

```

Very expensive. PostgreSQL must: <br>
- compare entire rows
- including large columns (JSON, text, bytea)
- Avoid doing DISTINCT on large rows.

Better: <br>
```sql
SELECT DISTINCT user_id FROM users;

```

## 4. DISTINCT combined with JOIN often explodes row count first
If you write: <br>

```sql
SELECT DISTINCT u.id
FROM users u
JOIN orders o ON o.user_id = u.id;

```

JOIN produces many duplicates ‚Üí DISTINCT removes them later. <br>

Better pattern: <br>

```sql
SELECT u.id
FROM users u
WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);

```

## 5. Increasing work_mem improves DISTINCT performance
```sql
SET work_mem = '256MB';

```

Bigger work_mem helps:
- hash-based DISTINCT (bigger hash table)
- sort-based DISTINCT (fewer disk spills)

# üß™ Let‚Äôs see a real internal example
```
SELECT DISTINCT city FROM users;

```

## What PostgreSQL does internally for Hashing<br>

- SeqScan on users ‚Üí stream all rows
- For each row:
    - take city value
    - hash(city)
- Insert hash ‚Üí check if exists
- Build a hash table like:

```
{
  "Hanoi": true,
  "Bangkok": true,
  "Tokyo": true,
  "Hanoi": (skip)
}
```
- Output unique keys.

## DISTINCT via Sorting
- Fetch all rows.
- Sort rows by the DISTINCT columns.
    - Sorting groups identical rows together.
    - PostgreSQL uses external merge sort if data is too large for memory.
- Scan sorted rows sequentially:
    - Compare each row with the previous.
    - Keep first occurrence, skip duplicates.

| id | city   |
| -- | ------ |
| 1  | London |
| 2  | Paris  |
| 3  | London |
| 4  | Berlin |

sort by city <br>

| id | city   |
| -- | ------ |
| 4  | Berlin |
| 1  | London |
| 3  | London |
| 2  | Paris  |

Scan & remove duplicates <br>

- Keep Berlin
- Keep first London, skip second
- Keep Paris

Result: Berlin, London, Paris <br>

Complexity: <br>
- Time: O(n log n)
- Space: depends on memory and external disk if needed



| Method                  | When                        | Operator                   | Memory behavior                   |
| ----------------------- | --------------------------- | -------------------------- | --------------------------------- |
| **Hash-based DISTINCT** | No ORDER BY, small datasets | `HashAggregate`            | Can spill if hash > work_mem      |
| **Sort-based DISTINCT** | ORDER BY, DISTINCT ON       | `Sort ‚Üí Unique`            | External merge sort if > work_mem |
| **DISTINCT ON**         | Postgres-only               | Requires sorting           | Must follow ORDER BY              |
| **Indexed DISTINCT**    | Index covers columns        | `Unique ‚Üí Index Only Scan` | Fastest, avoids full table        |
